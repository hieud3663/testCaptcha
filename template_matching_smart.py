from PIL import Image, ImageDraw
import numpy as np
import cv2
from skimage import feature, filters, measure
from scipy import ndimage
import os
from datetime import datetime

def find_gap_by_template_matching(main_image_path):
    """
    T√¨m gap b·∫±ng c√°ch matching m·∫£nh gh√©p v·ªõi v√πng tr√™n
    """
    print("=== T√åM GAP B·∫∞NG TEMPLATE MATCHING TH√îNG MINH ===")
    
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    print(f"üìè Image size: {w}x{h}")
    
    # B∆∞·ªõc 1: T√°ch m·∫£nh gh√©p v√† v√πng t√¨m ki·∫øm
    piece_region, search_region, piece_info = extract_piece_and_search_area(gray)
    
    if piece_region is None:
        print("‚ùå Kh√¥ng t√¨m th·∫•y m·∫£nh gh√©p")
        return None, None
    
    print(f"üß© Piece size: {piece_region.shape}")
    print(f"üîç Search area size: {search_region.shape}")
    
    # B∆∞·ªõc 2: Template matching ƒë·ªÉ t√¨m v·ªã tr√≠ kh·ªõp
    match_candidates = find_matching_positions(piece_region, search_region, piece_info)
    
    print(f"üéØ Found {len(match_candidates)} matching positions")
    
    # B∆∞·ªõc 3: Ki·ªÉm tra gap t·∫°i m·ªói v·ªã tr√≠ match
    gap_candidates = []
    for match in match_candidates:
        gaps = find_gaps_near_match(gray, match, piece_info)
        gap_candidates.extend(gaps)
    
    print(f"üîç Found {len(gap_candidates)} gap candidates")
    
    if not gap_candidates:
        print("‚ùå Kh√¥ng t√¨m th·∫•y gap candidates")
        return None, None
    
    # B∆∞·ªõc 4: Ch·ªçn gap t·ªët nh·∫•t
    best_gap = select_best_gap(gap_candidates, piece_info)
    
    # B∆∞·ªõc 5: Visualize k·∫øt qu·∫£
    visualize_template_matching_result(main_image_path, piece_info, match_candidates, gap_candidates, best_gap)
    
    print(f"\nüéØ K·∫æT QU·∫¢ TEMPLATE MATCHING:")
    print(f"Best gap position: ({best_gap['x']}, {best_gap['y']})")
    print(f"Gap score: {best_gap['score']:.1f}")
    print(f"Match confidence: {best_gap['match_confidence']:.3f}")
    
    return best_gap['x'], best_gap['y']

def extract_piece_and_search_area(gray):
    """
    T√°ch m·∫£nh gh√©p v√† v√πng t√¨m ki·∫øm
    """
    h, w = gray.shape
    
    # V√πng m·∫£nh gh√©p: 1/3 d∆∞·ªõi c·ªßa ·∫£nh
    piece_start_y = h * 2 // 3
    piece_region = gray[piece_start_y:h, :]
    
    # V√πng t√¨m ki·∫øm: 2/3 tr√™n c·ªßa ·∫£nh  
    search_region = gray[0:piece_start_y, :]
    
    # Ph√¢n t√≠ch m·∫£nh gh√©p ƒë·ªÉ l·∫•y template
    piece_info = analyze_piece_for_template(piece_region, piece_start_y)
    
    return piece_region, search_region, piece_info

def analyze_piece_for_template(piece_region, offset_y):
    """
    Ph√¢n t√≠ch m·∫£nh gh√©p ƒë·ªÉ t·∫°o template
    """
    h, w = piece_region.shape
    
    # T√¨m contour c·ªßa m·∫£nh gh√©p
    # Threshold ƒë·ªÉ t√°ch piece kh·ªèi background - th·ª≠ nhi·ªÅu method
    mean_val = np.mean(piece_region)
    std_val = np.std(piece_region)
    
    print(f"üîç Piece region stats: mean={mean_val:.1f}, std={std_val:.1f}")
    
    # Th·ª≠ multiple thresholds
    binary_methods = [
        piece_region < (mean_val - std_val * 0.5),  # Method 1
        piece_region < (mean_val - 30),             # Method 2  
        piece_region > (mean_val + std_val * 0.5),  # Method 3 (bright piece)
    ]
    
    best_template = None
    best_area = 0
    
    for i, binary in enumerate(binary_methods):
        print(f"üîç Trying threshold method {i+1}...")
        
        # Morphological operations
        from skimage import morphology
        binary_clean = morphology.opening(binary, morphology.disk(2))
        binary_clean = morphology.closing(binary_clean, morphology.disk(3))
        
        # T√¨m connected components
        labeled = measure.label(binary_clean)
        regions = measure.regionprops(labeled)
        
        if regions:
            largest_region = max(regions, key=lambda x: x.area)
            print(f"   Found region with area: {largest_region.area}")
            
            if largest_region.area > best_area and largest_region.area > 500:  # Min area threshold
                best_area = largest_region.area
                bbox = largest_region.bbox
                
                # Extract template t·ª´ bbox
                template = piece_region[bbox[0]:bbox[2], bbox[1]:bbox[3]]
                
                # Resize template n·∫øu c·∫ßn
                max_size = 50  # Smaller template for better matching
                if template.shape[0] > max_size or template.shape[1] > max_size:
                    scale_factor = min(max_size/template.shape[0], max_size/template.shape[1])
                    new_h = int(template.shape[0] * scale_factor)
                    new_w = int(template.shape[1] * scale_factor)
                    template = cv2.resize(template, (new_w, new_h))
                
                best_template = {
                    'template': template,
                    'bbox': bbox,
                    'offset_y': offset_y,
                    'area': largest_region.area,
                    'original_piece': piece_region,
                    'method': i+1
                }
    
    if best_template is None:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y piece region ph√π h·ª£p, d√πng crop t·ª´ center")
        # Fallback: crop t·ª´ center c·ªßa piece region
        center_h, center_w = h//2, w//2
        crop_size = 40
        template = piece_region[center_h-crop_size//2:center_h+crop_size//2,
                               center_w-crop_size//2:center_w+crop_size//2]
        
        best_template = {
            'template': template,
            'bbox': (center_h-crop_size//2, center_w-crop_size//2, center_h+crop_size//2, center_w+crop_size//2),
            'offset_y': offset_y,
            'area': crop_size * crop_size,
            'original_piece': piece_region,
            'method': 'fallback'
        }
    
    print(f"üß© Selected template (method {best_template['method']}): {best_template['template'].shape}")
    print(f"üìç Piece bbox: {best_template['bbox']}")
    
    return best_template

def find_matching_positions(piece_region, search_region, piece_info):
    """
    T√¨m v·ªã tr√≠ matching gi·ªØa piece v√† search area
    """
    template = piece_info['template']
    search_h, search_w = search_region.shape
    template_h, template_w = template.shape
    
    if template_h >= search_h or template_w >= search_w:
        print("‚ö†Ô∏è Template qu√° l·ªõn so v·ªõi search area")
        return []
    
    # Template matching v·ªõi OpenCV
    result = cv2.matchTemplate(search_region.astype(np.float32), 
                              template.astype(np.float32), 
                              cv2.TM_CCOEFF_NORMED)
    
    # Debug: in th√¥ng tin v·ªÅ template matching
    max_val = np.max(result)
    min_val = np.min(result)
    print(f"üîç Template matching stats: min={min_val:.3f}, max={max_val:.3f}")
    
    # T√¨m t·∫•t c·∫£ matches v·ªõi threshold th·∫•p h∆°n
    threshold = 0.3  # Threshold th·∫•p h∆°n ƒë·ªÉ t√¨m ƒë∆∞·ª£c matches
    locations = np.where(result >= threshold)
    
    matches = []
    for pt in zip(*locations[::-1]):  # (x, y)
        confidence = result[pt[1], pt[0]]
        
        # T·ªça ƒë·ªô center c·ªßa match
        center_x = pt[0] + template_w // 2
        center_y = pt[1] + template_h // 2
        
        matches.append({
            'x': center_x,
            'y': center_y,
            'confidence': confidence,
            'template_x': pt[0],
            'template_y': pt[1]
        })
    
    print(f"üîç Found {len(matches)} raw matches with threshold {threshold}")
    
    # Lo·∫°i b·ªè duplicates (matches g·∫ßn nhau)
    unique_matches = []
    for match in matches:
        is_duplicate = False
        for existing in unique_matches:
            distance = np.sqrt((match['x'] - existing['x'])**2 + (match['y'] - existing['y'])**2)
            if distance < 30:  # N·∫øu g·∫ßn nhau < 30px
                # Gi·ªØ match c√≥ confidence cao h∆°n
                if match['confidence'] > existing['confidence']:
                    unique_matches.remove(existing)
                    unique_matches.append(match)
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique_matches.append(match)
    
    # Sort theo confidence
    unique_matches.sort(key=lambda x: x['confidence'], reverse=True)
    
    print(f"üéØ Template matching results:")
    for i, match in enumerate(unique_matches[:5]):
        print(f"  {i+1}. ({match['x']}, {match['y']}) - Confidence: {match['confidence']:.3f}")
    
    return unique_matches

def find_gaps_near_match(gray, match, piece_info):
    """
    T√¨m gaps g·∫ßn v·ªã tr√≠ match
    """
    h, w = gray.shape
    match_x, match_y = match['x'], match['y']
    
    # T√¨m gaps trong v√πng quanh match
    search_radius = 50
    gap_candidates = []
    
    # K√≠ch th∆∞·ªõc gap d·ª± ki·∫øn (d·ª±a tr√™n piece)
    template = piece_info['template']
    expected_gap_size = min(template.shape[0], template.shape[1])
    
    window_sizes = [
        max(16, expected_gap_size - 8),
        expected_gap_size,
        min(50, expected_gap_size + 8)
    ]
    
    for window_size in window_sizes:
        half_size = window_size // 2
        
        for dy in range(-search_radius, search_radius + 1, 4):
            for dx in range(-search_radius, search_radius + 1, 4):
                
                gap_x = match_x + dx
                gap_y = match_y + dy
                
                # Check bounds
                if (gap_x - half_size < 0 or gap_x + half_size >= w or
                    gap_y - half_size < 0 or gap_y + half_size >= h):
                    continue
                
                # Extract window
                window = gray[gap_y - half_size:gap_y + half_size,
                             gap_x - half_size:gap_x + half_size]
                
                if window.shape[0] != window_size or window.shape[1] != window_size:
                    continue
                
                # Analyze gap
                gap_score = analyze_gap_near_match(window, gap_x, gap_y, match, piece_info)
                
                if gap_score > 70:  # Threshold cao cho gap ch·∫•t l∆∞·ª£ng
                    distance_to_match = np.sqrt((gap_x - match_x)**2 + (gap_y - match_y)**2)
                    
                    gap_candidates.append({
                        'x': gap_x,
                        'y': gap_y,
                        'score': gap_score,
                        'window_size': window_size,
                        'distance_to_match': distance_to_match,
                        'match_confidence': match['confidence'],
                        'match_x': match_x,
                        'match_y': match_y
                    })
    
    return gap_candidates

def analyze_gap_near_match(window, gap_x, gap_y, match, piece_info):
    """
    Ph√¢n t√≠ch gap g·∫ßn v·ªã tr√≠ match
    """
    window_size = window.shape[0]
    window_mean = np.mean(window)
    window_std = np.std(window)
    
    # Background comparison (l·∫•y t·ª´ c√°c v√πng xung quanh)
    bg_sample = piece_info['original_piece'][:20, :20]  # Sample t·ª´ piece region
    bg_mean = np.mean(bg_sample)
    
    # 1. Gap ph·∫£i t·ªëi h∆°n background
    darkness_ratio = (bg_mean - window_mean) / bg_mean if bg_mean > 0 else 0
    darkness_score = max(0, min(100, darkness_ratio * 300))
    
    # 2. Gap ph·∫£i ƒë·ªìng ƒë·ªÅu
    uniformity_score = max(0, 100 - window_std * 2)
    
    # 3. H√¨nh d·∫°ng vu√¥ng
    row_means = [np.mean(window[i, :]) for i in range(window_size)]
    col_means = [np.mean(window[:, j]) for j in range(window_size)]
    shape_score = max(0, 100 - np.std(row_means) * 5 - np.std(col_means) * 5)
    
    # 4. Kho·∫£ng c√°ch ƒë·∫øn match (g·∫ßn match t·ªët h∆°n)
    distance_to_match = np.sqrt((gap_x - match['x'])**2 + (gap_y - match['y'])**2)
    distance_score = max(0, 100 - distance_to_match * 2)
    
    # 5. Confidence c·ªßa match
    match_score = match['confidence'] * 100
    
    # T·ªïng h·ª£p
    total_score = (
        darkness_score * 0.25 +
        uniformity_score * 0.25 +
        shape_score * 0.20 +
        distance_score * 0.15 +
        match_score * 0.15
    )
    
    return total_score

def select_best_gap(gap_candidates, piece_info):
    """
    Ch·ªçn gap t·ªët nh·∫•t
    """
    # Sort theo score t·ªïng h·ª£p
    gap_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"üèÜ Top 5 gap candidates:")
    for i, gap in enumerate(gap_candidates[:5]):
        print(f"  {i+1}. ({gap['x']}, {gap['y']}) - Score: {gap['score']:.1f} - Match conf: {gap['match_confidence']:.3f}")
    
    return gap_candidates[0]

def visualize_template_matching_result(main_image_path, piece_info, matches, gaps, best_gap):
    """
    Visualize k·∫øt qu·∫£ template matching
    """
    try:
        img = Image.open(main_image_path).convert('RGB')
        draw = ImageDraw.Draw(img)
        
        # V·∫Ω piece region
        piece_bbox = piece_info['bbox']
        offset_y = piece_info['offset_y']
        draw.rectangle([
            piece_bbox[1], offset_y + piece_bbox[0],
            piece_bbox[3], offset_y + piece_bbox[2]
        ], outline=(255, 255, 0), width=2)  # V√†ng cho piece
        
        # V·∫Ω matches
        for i, match in enumerate(matches[:3]):  # Top 3 matches
            color = (0, 255, 0) if i == 0 else (0, 255, 255)  # Xanh l√° cho best, cyan cho others
            x, y = match['x'], match['y']
            draw.ellipse([x-8, y-8, x+8, y+8], outline=color, width=2)
            draw.text((x+10, y-10), f"M{i+1}", fill=color)
        
        # V·∫Ω gap candidates
        for i, gap in enumerate(gaps[:10]):
            if gap == best_gap:
                color = (255, 0, 0)  # ƒê·ªè cho best gap
                radius = 12
            else:
                color = (255, 165, 0)  # Cam cho other gaps
                radius = 6
            
            x, y = gap['x'], gap['y']
            draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                        outline=color, width=3)
        
        # Info text
        info_text = [
            f"Best Gap: ({best_gap['x']}, {best_gap['y']})",
            f"Score: {best_gap['score']:.1f}",
            f"Match Conf: {best_gap['match_confidence']:.3f}",
            f"Template Size: {piece_info['template'].shape}"
        ]
        
        for i, text in enumerate(info_text):
            draw.rectangle([10, 10+i*20, 300, 25+i*20], fill=(0, 0, 0), outline=(255, 255, 255))
            draw.text((12, 12+i*20), text, fill=(255, 255, 255))
        
        # Save
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"results/template_matching_{timestamp}.png"
        if not os.path.exists("results"):
            os.makedirs("results")
        img.save(output_path)
        
        print(f"‚úÖ Saved template matching result: {output_path}")
        
    except Exception as e:
        print(f"‚ùå Error saving visualization: {e}")

# S·ª≠ d·ª•ng
if __name__ == "__main__":
    main_image = "image.png"
    
    print("üöÄ Kh·ªüi ƒë·ªông template matching th√¥ng minh...")
    
    x, y = find_gap_by_template_matching(main_image)
    
    if x is not None and y is not None:
        print(f"\nüèÜ TH√ÄNH C√îNG!")
        print(f"Gap position found: ({x}, {y})")
        print(f"üì∏ Xem file visualization ƒë·ªÉ ki·ªÉm tra k·∫øt qu·∫£!")
    else:
        print("‚ùå Th·∫•t b·∫°i! Kh√¥ng t√¨m th·∫•y gap")
