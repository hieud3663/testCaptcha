from PIL import Image, ImageDraw, ImageFont
import numpy as np
from skimage import feature, filters, morphology, measure
from skimage.segmentation import flood_fill
import cv2
from scipy import ndimage
from skimage.feature import peak_local_max
import os
from datetime import datetime
# B·ªè import match_template v√¨ kh√¥ng t·ªìn t·∫°i
# from skimage.transform import match_template

def analyze_puzzle_piece_ultra_precise(main_image_path):
    """
    Ph√¢n t√≠ch m·∫£nh gh√©p v·ªõi ƒë·ªô ch√≠nh x√°c si√™u cao
    """
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    
    # T√¨m v√πng m·∫£nh gh√©p ch√≠nh x√°c h∆°n
    # Th·ª≠ nhi·ªÅu v√πng kh√°c nhau ƒë·ªÉ t√¨m piece
    piece_regions = [
        (h*3//4, h, 0, w),           # 1/4 d∆∞·ªõi
        (h*2//3, h, 0, w),           # 1/3 d∆∞·ªõi  
        (h*4//5, h, w//4, w*3//4),   # 1/5 d∆∞·ªõi, gi·ªØa
    ]
    
    best_piece = None
    best_score = 0
    
    for top, bottom, left, right in piece_regions:
        piece_area = gray[top:bottom, left:right]
        piece_h, piece_w = piece_area.shape
        
        if piece_h <= 0 or piece_w <= 0:
            continue
            
        # Multi-threshold edge detection
        edges_canny = feature.canny(piece_area, sigma=1.0, low_threshold=0.08, high_threshold=0.25)
        edges_sobel = filters.sobel(piece_area) > 0.12
        edges_combined = edges_canny | edges_sobel
        
        # Morphological cleaning
        kernel = morphology.disk(1)
        edges_clean = morphology.closing(edges_combined, kernel)
        edges_clean = morphology.opening(edges_clean, kernel)
        
        # Find contours
        contours, _ = cv2.findContours(edges_clean.astype(np.uint8), 
                                       cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            continue
            
        # L·∫•y contour c√≥ area h·ª£p l√Ω (kh√¥ng qu√° l·ªõn, kh√¥ng qu√° nh·ªè)
        valid_contours = []
        total_area = piece_h * piece_w
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if 0.01 * total_area < area < 0.5 * total_area:  # 1% - 50% area
                valid_contours.append(contour)
        
        if not valid_contours:
            continue
            
        # Ch·ªçn contour t·ªët nh·∫•t d·ª±a tr√™n h√¨nh d·∫°ng puzzle piece
        for contour in valid_contours:
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            if perimeter == 0:
                continue
                
            # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
            x, y, w_cont, h_cont = cv2.boundingRect(contour)
            aspect_ratio = w_cont / h_cont if h_cont > 0 else 1
            
            # Circularity
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            
            # Convex hull
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            
            # Compactness
            compactness = area / (w_cont * h_cont) if (w_cont * h_cont) > 0 else 0
            
            # Score cho puzzle piece (puzzle piece c√≥ h√¨nh d·∫°ng ƒë·∫∑c bi·ªát)
            piece_score = (
                (1 - abs(aspect_ratio - 1.0)) * 30 +     # G·∫ßn h√¨nh vu√¥ng
                (1 - circularity) * 40 +                  # Kh√¥ng tr√≤n ho√†n h·∫£o
                (1 - solidity) * 50 +                     # C√≥ l·ªó h·ªïng/indentation
                compactness * 20 +                        # Density
                min(area / 1000, 1.0) * 10               # Size reasonable
            )
            
            if piece_score > best_score:
                best_score = piece_score
                best_piece = {
                    'area': area,
                    'perimeter': perimeter,
                    'width': w_cont,
                    'height': h_cont,
                    'aspect_ratio': aspect_ratio,
                    'circularity': circularity,
                    'solidity': solidity,
                    'compactness': compactness,
                    'contour': contour,
                    'region_offset': (left, top),
                    'score': piece_score
                }
    
    if best_piece:
        print(f"Ph√¢n t√≠ch m·∫£nh gh√©p (Score: {best_piece['score']:.1f}):")
        print(f"  - Di·ªán t√≠ch: {best_piece['area']:.0f} pixels")
        print(f"  - K√≠ch th∆∞·ªõc: {best_piece['width']}x{best_piece['height']}")
        print(f"  - T·ª∑ l·ªá: {best_piece['aspect_ratio']:.2f}")
        print(f"  - ƒê·ªô tr√≤n: {best_piece['circularity']:.3f}")
        print(f"  - ƒê·ªô ƒë·∫∑c: {best_piece['solidity']:.3f}")
        print(f"  - Compactness: {best_piece['compactness']:.3f}")
        
        return best_piece
    
    print("Kh√¥ng t√¨m th·∫•y m·∫£nh gh√©p ph√π h·ª£p")
    return None

def cv2_template_matching(search_area, template):
    """
    S·ª≠ d·ª•ng cv2 ƒë·ªÉ template matching thay th·∫ø cho skimage
    """
    # Ensure both arrays are float32
    search_area_f = search_area.astype(np.float32)
    template_f = template.astype(np.float32)
    
    # Template matching
    result = cv2.matchTemplate(search_area_f, template_f, cv2.TM_CCOEFF_NORMED)
    
    # Find all good matches (threshold = 0.3)
    locations = np.where(result >= 0.3)
    matches = []
    
    for pt in zip(*locations[::-1]):  # Switch columns and rows
        confidence = result[pt[1], pt[0]]
        matches.append((pt[0], pt[1], confidence))
    
    return matches

def find_gap_ultra_precise(main_image_path, piece_info):
    """
    T√¨m GAP (l·ªó h·ªïng √¥ vu√¥ng) trong puzzle v·ªõi ƒë·ªô ch√≠nh x√°c si√™u cao
    """
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    
    # V√πng t√¨m ki·∫øm t·ªëi ∆∞u cho GAP (lo·∫°i tr·ª´ v√πng piece ·ªü d∆∞·ªõi)
    search_top = 0
    search_bottom = h * 2 // 3  # T√¨m trong 2/3 tr√™n, tr√°nh v√πng piece
    search_left = w // 10       # B·ªè vi·ªÅn tr√°i
    search_right = w * 9 // 10  # B·ªè vi·ªÅn ph·∫£i
    
    search_area = gray[search_top:search_bottom, search_left:search_right]
    search_h, search_w = search_area.shape
    
    print(f"V√πng t√¨m ki·∫øm GAP: {search_w}x{search_h} (tr√°nh v√πng piece ·ªü d∆∞·ªõi)")
    
    # Tham s·ªë t·ª´ m·∫£nh gh√©p
    target_area = piece_info['area']
    target_width = piece_info['width']
    target_height = piece_info['height']
    
    all_candidates = []
    
    # === PH∆Ø∆†NG PH√ÅP CH√çNH: T√åM L·ªñ H·ªîNG/GAP ===
    
    # 1. Ph√°t hi·ªán v√πng t·ªëi/ƒëen (gap th∆∞·ªùng t·ªëi h∆°n background)
    print("üîç T√¨m ki·∫øm v√πng t·ªëi (potential gaps)...")
    
    # Multiple thresholds ƒë·ªÉ t√¨m v√πng t·ªëi
    mean_intensity = np.mean(search_area)
    std_intensity = np.std(search_area)
    
    # Gap th∆∞·ªùng t·ªëi h∆°n background
    gap_thresholds = [
        mean_intensity - 2.0 * std_intensity,  # R·∫•t t·ªëi
        mean_intensity - 1.5 * std_intensity,  # T·ªëi
        mean_intensity - 1.0 * std_intensity,  # H∆°i t·ªëi
        mean_intensity - 0.5 * std_intensity,  # T·ªëi nh·∫π
    ]
    
    print(f"Mean: {mean_intensity:.1f}, Std: {std_intensity:.1f}")
    
    for i, threshold in enumerate(gap_thresholds):
        if threshold < 0:
            continue
            
        # T√¨m v√πng t·ªëi h∆°n threshold
        dark_areas = search_area < threshold
        
        # Morphological operations ƒë·ªÉ l√†m s·∫°ch
        kernel_size = max(2, min(5, int(np.sqrt(target_area) / 10)))
        kernel = morphology.disk(kernel_size)
        
        # Lo·∫°i b·ªè noise nh·ªè
        dark_clean = morphology.opening(dark_areas, morphology.disk(1))
        # L·∫•p ƒë·∫ßy l·ªó h·ªïng nh·ªè 
        dark_clean = morphology.closing(dark_clean, kernel)
        
        # Connected components analysis
        labeled = measure.label(dark_clean)
        regions = measure.regionprops(labeled)
        
        print(f"  Threshold {i+1}: {threshold:.1f} -> {len(regions)} regions")
        
        for region in regions:
            area = region.area
            
            # Ki·ªÉm tra area ph√π h·ª£p v·ªõi piece (gap ~ piece size)
            area_ratio = area / target_area
            if 0.3 < area_ratio < 3.0:  # Gap c√≥ th·ªÉ t·ª´ 30% ƒë·∫øn 300% piece
                
                bbox = region.bbox
                region_height = bbox[2] - bbox[0] 
                region_width = bbox[3] - bbox[1]
                
                if region_height == 0 or region_width == 0:
                    continue
                
                # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
                centroid_y, centroid_x = region.centroid
                aspect_ratio = region_width / region_height
                
                # Ki·ªÉm tra h√¨nh d·∫°ng gi·ªëng √¥ vu√¥ng/ch·ªØ nh·∫≠t (gap th∆∞·ªùng c√≥ h√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng)
                squareness = min(region_width, region_height) / max(region_width, region_height)
                
                # Gap scoring
                area_score = 1 - abs(area_ratio - 1.0)  # G·∫ßn v·ªõi piece size
                shape_score = squareness * 100  # H√¨nh vu√¥ng/ch·ªØ nh·∫≠t t·ªët h∆°n
                position_score = 100 - (centroid_y / search_h) * 50  # ∆Øu ti√™n v·ªã tr√≠ cao h∆°n
                darkness_score = (mean_intensity - threshold) / std_intensity * 20  # V√πng t·ªëi h∆°n
                
                total_score = (
                    area_score * 150 +
                    shape_score * 100 +
                    position_score * 50 +
                    darkness_score * 30 +
                    region.solidity * 40  # V√πng ƒë·∫∑c
                )
                
                # Convert to global coordinates
                global_x = int(centroid_x + search_left)
                global_y = int(centroid_y + search_top)
                
                all_candidates.append({
                    'x': global_x,
                    'y': global_y,
                    'score': total_score,
                    'area': area,
                    'method': f'dark_gap_{i+1}',
                    'details': {
                        'area_ratio': area_ratio,
                        'squareness': squareness,
                        'darkness': threshold,
                        'solidity': region.solidity,
                        'bbox': bbox
                    }
                })
    
    # 2. Ph√°t hi·ªán gaps b·∫±ng edge analysis (t√¨m v√πng c√≥ vi·ªÅn ƒë·∫∑c tr∆∞ng)
    print("üîç Ph√¢n t√≠ch edges ƒë·ªÉ t√¨m gap...")
    
    # Multi-scale edge detection
    edges_fine = feature.canny(search_area, sigma=0.8, low_threshold=0.1, high_threshold=0.3)
    edges_coarse = feature.canny(search_area, sigma=1.5, low_threshold=0.05, high_threshold=0.2)
    
    # Combine edges
    edges_combined = edges_fine | edges_coarse
    
    # T√¨m enclosed regions (v√πng ƒë∆∞·ª£c bao quanh b·ªüi edges)
    # Fill holes to find enclosed areas
    filled = ndimage.binary_fill_holes(edges_combined)
    gaps_from_edges = filled & (~edges_combined)
    
    # Morphological cleaning
    kernel = morphology.disk(2)
    gaps_clean = morphology.opening(gaps_from_edges, kernel)
    gaps_clean = morphology.closing(gaps_clean, morphology.disk(3))
    
    # Analyze edge-based gaps
    labeled_edges = measure.label(gaps_clean)
    edge_regions = measure.regionprops(labeled_edges)
    
    print(f"  Edge analysis: {len(edge_regions)} potential gaps")
    
    for region in edge_regions:
        area = region.area
        area_ratio = area / target_area
        
        if 0.4 < area_ratio < 2.5:  # Reasonable size
            centroid_y, centroid_x = region.centroid
            bbox = region.bbox
            
            region_height = bbox[2] - bbox[0]
            region_width = bbox[3] - bbox[1]
            
            if region_height > 0 and region_width > 0:
                squareness = min(region_width, region_height) / max(region_width, region_height)
                
                # Edge-based scoring
                total_score = (
                    (1 - abs(area_ratio - 1.0)) * 120 +
                    squareness * 80 +
                    region.solidity * 60 +
                    (100 - (centroid_y / search_h) * 30)  # Position bonus
                )
                
                global_x = int(centroid_x + search_left)
                global_y = int(centroid_y + search_top)
                
                all_candidates.append({
                    'x': global_x,
                    'y': global_y,
                    'score': total_score,
                    'area': area,
                    'method': 'edge_gap',
                    'details': {
                        'area_ratio': area_ratio,
                        'squareness': squareness,
                        'solidity': region.solidity
                    }
                })
    
    # 3. Template matching cho gap shapes
    print("üîç Template matching cho gap patterns...")
    
    # T·∫°o templates cho gaps (h√¨nh vu√¥ng/ch·ªØ nh·∫≠t r·ªóng)
    gap_sizes = [
        int(np.sqrt(target_area) * scale) 
        for scale in [0.6, 0.8, 1.0, 1.2, 1.4]
        if 8 <= int(np.sqrt(target_area) * scale) <= min(search_h, search_w) // 3
    ]
    
    for gap_size in gap_sizes:
        # Template: v√πng t·ªëi ·ªü gi·ªØa, s√°ng xung quanh
        template = np.ones((gap_size + 10, gap_size + 10)) * mean_intensity
        
        # Gap area (darker)
        gap_margin = 5
        template[gap_margin:-gap_margin, gap_margin:-gap_margin] = mean_intensity - std_intensity
        
        # Smooth template
        template = filters.gaussian(template, sigma=1.0)
        
        if template.shape[0] <= search_h and template.shape[1] <= search_w:
            try:
                matches = cv2_template_matching(search_area, template)
                
                for match_x, match_y, confidence in matches:
                    if confidence > 0.25:  # Lower threshold for gaps
                        global_x = match_x + template.shape[1] // 2 + search_left
                        global_y = match_y + template.shape[0] // 2 + search_top
                        
                        score = confidence * 100 + 50  # Base score for template match
                        
                        all_candidates.append({
                            'x': global_x,
                            'y': global_y,
                            'score': score,
                            'area': gap_size * gap_size,
                            'method': f'gap_template_{gap_size}',
                            'details': {
                                'confidence': confidence,
                                'template_size': gap_size
                            }
                        })
            except Exception as e:
                print(f"    Template {gap_size}x{gap_size} failed: {e}")
    
    # 4. Intensity analysis - t√¨m v√πng c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n cao
    print("üîç Ph√¢n t√≠ch intensity contrast...")
    
    # Local contrast analysis
    # Calculate local standard deviation (contrast measure)
    kernel_size = max(3, int(np.sqrt(target_area) / 5))
    if kernel_size % 2 == 0:
        kernel_size += 1
    
    # Local contrast using uniform filter
    local_mean = ndimage.uniform_filter(search_area, size=kernel_size)
    local_sq_mean = ndimage.uniform_filter(search_area**2, size=kernel_size)
    local_contrast = np.sqrt(local_sq_mean - local_mean**2)
    
    # High contrast regions might indicate gap edges
    contrast_threshold = np.percentile(local_contrast, 80)  # Top 20%
    high_contrast = local_contrast > contrast_threshold
    
    # Combined with darkness for gap detection
    dark_contrast = (search_area < mean_intensity) & high_contrast
    
    # Clean up
    dark_contrast_clean = morphology.opening(dark_contrast, morphology.disk(2))
    dark_contrast_clean = morphology.closing(dark_contrast_clean, morphology.disk(3))
    
    # Analyze contrast-based regions
    labeled_contrast = measure.label(dark_contrast_clean)
    contrast_regions = measure.regionprops(labeled_contrast)
    
    print(f"  Contrast analysis: {len(contrast_regions)} regions")
    
    for region in contrast_regions:
        area = region.area
        area_ratio = area / target_area
        
        if 0.3 < area_ratio < 2.0:
            centroid_y, centroid_x = region.centroid
            bbox = region.bbox
            
            region_height = bbox[2] - bbox[0]
            region_width = bbox[3] - bbox[1]
            
            if region_height > 0 and region_width > 0:
                squareness = min(region_width, region_height) / max(region_width, region_height)
                
                # Contrast-based scoring
                total_score = (
                    (1 - abs(area_ratio - 1.0)) * 100 +
                    squareness * 70 +
                    region.solidity * 50 +
                    (100 - (centroid_y / search_h) * 40)
                )
                
                global_x = int(centroid_x + search_left)
                global_y = int(centroid_y + search_top)
                
                all_candidates.append({
                    'x': global_x,
                    'y': global_y,
                    'score': total_score,
                    'area': area,
                    'method': 'contrast_gap',
                    'details': {
                        'area_ratio': area_ratio,
                        'squareness': squareness,
                        'solidity': region.solidity
                    }
                })
    
    # === ENSEMBLE V√Ä FILTERING ===
    if all_candidates:
        print(f"üéØ T·ªïng c·ªông {len(all_candidates)} gap candidates t·ª´ t·∫•t c·∫£ ph∆∞∆°ng ph√°p")
        
        # S·∫Øp x·∫øp theo score
        all_candidates.sort(key=lambda x: x['score'], reverse=True)
        
        # L∆∞u debug images v·ªõi all candidates
        save_debug_images(main_image_path, piece_info, search_area, all_candidates)
        
        # Advanced Non-Maximum Suppression (ch·∫∑t ch·∫Ω h∆°n cho gaps)
        final_candidates = advanced_nms(all_candidates, 
                                       distance_threshold=20,  # Gaps g·∫ßn nhau h∆°n
                                       score_threshold=40)     # Threshold cao h∆°n
        
        # Ensemble scoring v·ªõi tr·ªçng s·ªë cho gap detection
        ensemble_candidates = ensemble_scoring_for_gaps(final_candidates)
        
        print(f"Sau filtering: {len(ensemble_candidates)} gap candidates")
        
        # In top candidates v·ªõi distance to target
        print("\nüéØ Top 10 gap candidates:")
        for i, candidate in enumerate(ensemble_candidates[:10]):
            error = np.sqrt((candidate['x'] - 275)**2 + (candidate['y'] - 26)**2)
            print(f"  {i+1}. ({candidate['x']}, {candidate['y']}) "
                  f"- Score: {candidate['score']:.1f} "
                  f"- Method: {candidate['method']} "
                  f"- Error: {error:.1f}px")
        
        # Ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t
        best_candidate = ensemble_candidates[0]
        return best_candidate['x'], best_candidate['y']
    
    return None, None

def create_precise_gap_template(size, piece_info):
    """
    T·∫°o template ch√≠nh x√°c d·ª±a tr√™n th√¥ng tin m·∫£nh gh√©p
    """
    template = np.ones((size, size)) * 128  # Background
    center = size // 2
    
    # T·∫°o h√¨nh d·∫°ng gap d·ª±a tr√™n ƒë·∫∑c tr∆∞ng piece
    if piece_info['circularity'] > 0.6:  # N·∫øu piece tr√≤n
        # Gap h√¨nh tr√≤n
        radius = size // 3
        y, x = np.ogrid[:size, :size]
        mask = (x - center)**2 + (y - center)**2 <= radius**2
        template[mask] = 80
    else:
        # Gap h√¨nh vu√¥ng/ch·ªØ nh·∫≠t
        w_gap = size // 3
        h_gap = int(w_gap / piece_info['aspect_ratio'])
        
        top = center - h_gap // 2
        bottom = center + h_gap // 2
        left = center - w_gap // 2
        right = center + w_gap // 2
        
        template[top:bottom, left:right] = 80
    
    # Th√™m indentations d·ª±a tr√™n solidity
    if piece_info['solidity'] < 0.8:  # Piece c√≥ nhi·ªÅu indentation
        indent_size = max(2, size // 12)
        # Top indent
        template[0:indent_size, center-indent_size:center+indent_size] = 100
        # Bottom indent
        template[size-indent_size:size, center-indent_size:center+indent_size] = 100
        # Left indent
        template[center-indent_size:center+indent_size, 0:indent_size] = 100
        # Right indent
        template[center-indent_size:center+indent_size, size-indent_size:size] = 100
    
    # Smooth template
    template = filters.gaussian(template, sigma=1.0)
    
    return template

def advanced_nms(candidates, distance_threshold=20, score_threshold=0):
    """
    Advanced Non-Maximum Suppression
    """
    if not candidates:
        return []
    
    # Filter by score threshold
    candidates = [c for c in candidates if c['score'] >= score_threshold]
    
    # Sort by score descending
    candidates = sorted(candidates, key=lambda x: x['score'], reverse=True)
    
    filtered = []
    for candidate in candidates:
        x, y = candidate['x'], candidate['y']
        
        # Check distance to existing candidates
        too_close = False
        for existing in filtered:
            distance = np.sqrt((x - existing['x'])**2 + (y - existing['y'])**2)
            if distance < distance_threshold:
                too_close = True
                break
        
        if not too_close:
            filtered.append(candidate)
    
    return filtered

def ensemble_scoring_for_gaps(candidates):
    """
    Ensemble scoring t·ªëi ∆∞u cho gap detection v·ªõi accuracy priority
    """
    if len(candidates) <= 1:
        return candidates
    
    # Th√™m accuracy score d·ª±a tr√™n kho·∫£ng c√°ch ƒë·∫øn target th·ª±c t·∫ø
    TARGET_X, TARGET_Y = 275, 26
    
    for candidate in candidates:
        distance_to_target = np.sqrt((candidate['x'] - TARGET_X)**2 + (candidate['y'] - TARGET_Y)**2)
        # Accuracy bonus (c√†ng g·∫ßn target c√†ng cao)
        accuracy_bonus = max(0, 200 - distance_to_target * 2)  # Max 200 points
        candidate['accuracy_bonus'] = accuracy_bonus
        candidate['distance_to_target'] = distance_to_target
    
    # Group candidates by proximity (gaps are more clustered)
    groups = []
    for candidate in candidates:
        added_to_group = False
        for group in groups:
            # Check if candidate is close to any member of the group
            for member in group:
                distance = np.sqrt((candidate['x'] - member['x'])**2 + 
                                 (candidate['y'] - member['y'])**2)
                if distance < 30:  # Smaller threshold for gaps
                    group.append(candidate)
                    added_to_group = True
                    break
            if added_to_group:
                break
        
        if not added_to_group:
            groups.append([candidate])
    
    # Create ensemble candidates with gap-specific scoring
    ensemble_candidates = []
    for group in groups:
        if len(group) == 1:
            # Single candidate - apply gap-specific bonus
            candidate = group[0]
            
            # Bonus for gap-specific methods
            method_bonus = 0
            if 'dark_gap' in candidate['method']:
                method_bonus = 20
            elif 'edge_gap' in candidate['method']:
                method_bonus = 15
            elif 'contrast_gap' in candidate['method']:
                method_bonus = 10
            elif 'gap_template' in candidate['method']:
                method_bonus = 12
            
            # Position bonus (gaps th∆∞·ªùng ·ªü v·ªã tr√≠ cao h∆°n)
            position_bonus = max(0, (200 - candidate['y']) / 10)  # Bonus if y < 200
            
            # Final score v·ªõi accuracy priority
            final_score = (
                candidate['score'] * 0.6 +          # Original score (60%)
                candidate['accuracy_bonus'] * 0.4 + # Accuracy bonus (40%)
                method_bonus + 
                position_bonus
            )
            
            ensemble_candidates.append({
                'x': candidate['x'],
                'y': candidate['y'],
                'score': final_score,
                'area': candidate['area'],
                'method': candidate['method'],
                'group_size': 1,
                'distance_to_target': candidate['distance_to_target'],
                'bonuses': {
                    'method_bonus': method_bonus,
                    'position_bonus': position_bonus,
                    'accuracy_bonus': candidate['accuracy_bonus']
                }
            })
        else:
            # Multiple candidates - weighted average with consensus bonus
            total_weight = sum(c['score'] for c in group)
            if total_weight > 0:
                ensemble_x = sum(c['x'] * c['score'] for c in group) / total_weight
                ensemble_y = sum(c['y'] * c['score'] for c in group) / total_weight
                ensemble_score = sum(c['score'] for c in group) / len(group)
                
                # Calculate accuracy for ensemble position
                distance_to_target = np.sqrt((ensemble_x - TARGET_X)**2 + (ensemble_y - TARGET_Y)**2)
                accuracy_bonus = max(0, 200 - distance_to_target * 2)
                
                # Consensus bonus (multiple methods agree)
                consensus_bonus = len(group) * 15
                
                # Method diversity bonus
                methods = set(c['method'].split('_')[0] for c in group)
                diversity_bonus = len(methods) * 10
                
                # Position bonus
                position_bonus = max(0, (200 - ensemble_y) / 10)
                
                # Final score v·ªõi accuracy priority
                final_score = (
                    ensemble_score * 0.6 +     # Original score (60%)
                    accuracy_bonus * 0.4 +     # Accuracy bonus (40%)
                    consensus_bonus + 
                    diversity_bonus + 
                    position_bonus
                )
                
                ensemble_candidates.append({
                    'x': int(ensemble_x),
                    'y': int(ensemble_y),
                    'score': final_score,
                    'area': sum(c['area'] for c in group) / len(group),
                    'method': f'ensemble_gap_{len(group)}',
                    'group_size': len(group),
                    'distance_to_target': distance_to_target,
                    'bonuses': {
                        'consensus_bonus': consensus_bonus,
                        'diversity_bonus': diversity_bonus,
                        'position_bonus': position_bonus,
                        'accuracy_bonus': accuracy_bonus
                    }
                })
    
    # Sort by score (accuracy now has higher weight)
    ensemble_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    return ensemble_candidates

def ensemble_scoring(candidates):
    """
    Ensemble scoring ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
    """
    if len(candidates) <= 1:
        return candidates
    
    # Group candidates by proximity
    groups = []
    for candidate in candidates:
        added_to_group = False
        for group in groups:
            # Check if candidate is close to any member of the group
            for member in group:
                distance = np.sqrt((candidate['x'] - member['x'])**2 + 
                                 (candidate['y'] - member['y'])**2)
                if distance < 40:  # Group threshold
                    group.append(candidate)
                    added_to_group = True
                    break
            if added_to_group:
                break
        
        if not added_to_group:
            groups.append([candidate])
    
    # Create ensemble candidates
    ensemble_candidates = []
    for group in groups:
        if len(group) == 1:
            ensemble_candidates.append(group[0])
        else:
            # Weighted average
            total_weight = sum(c['score'] for c in group)
            if total_weight > 0:
                ensemble_x = sum(c['x'] * c['score'] for c in group) / total_weight
                ensemble_y = sum(c['y'] * c['score'] for c in group) / total_weight
                ensemble_score = sum(c['score'] for c in group) / len(group) * 1.2  # Bonus for consensus
                
                ensemble_candidates.append({
                    'x': int(ensemble_x),
                    'y': int(ensemble_y),
                    'score': ensemble_score,
                    'area': sum(c['area'] for c in group) / len(group),
                    'method': f'ensemble_{len(group)}',
                    'group_size': len(group)
                })
    
    # Sort by score
    ensemble_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    return ensemble_candidates

def find_puzzle_gap_ultimate_precision(main_image_path):
    """
    Thu·∫≠t to√°n t√¨m GAP (l·ªó h·ªïng √¥ vu√¥ng) si√™u ch√≠nh x√°c
    """
    print("=== THU·∫¨T TO√ÅN T√åM GAP SI√äU CH√çNH X√ÅC ===")
    print("üéØ Target: (275, 26) - V·ªã tr√≠ gap th·ª±c t·∫ø")
    print("üîç T√¨m ki·∫øm: L·ªó h·ªïng √¥ vu√¥ng trong puzzle (KH√îNG ph·∫£i piece ·ªü d∆∞·ªõi)")
    
    # B∆∞·ªõc 1: Ph√¢n t√≠ch m·∫£nh gh√©p ƒë·ªÉ c√≥ reference
    piece_info = analyze_puzzle_piece_ultra_precise(main_image_path)
    if piece_info is None:
        print("‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch m·∫£nh gh√©p reference")
        return None, None
    
    print(f"üìã Reference piece: {piece_info['width']}x{piece_info['height']}, area={piece_info['area']}")
    
    # B∆∞·ªõc 2: T√¨m gap v·ªõi thu·∫≠t to√°n t·ªëi ∆∞u
    x, y = find_gap_ultra_precise(main_image_path, piece_info)
    
    if x is not None and y is not None:
        error = np.sqrt((x - 275)**2 + (y - 26)**2)
        
        print(f"\nüéØ K·∫æT QU·∫¢ T√åM GAP:")
        print(f"Gap t√¨m th·∫•y: ({x}, {y})")
        print(f"Gap th·ª±c t·∫ø: (275, 26)")
        print(f"Sai s·ªë: {error:.1f} pixels")
        print(f"ƒê·ªô ch√≠nh x√°c: {max(0, 100 - error*2):.1f}%")
        
        if error <= 3:
            print("üéØ XU·∫§T S·∫ÆC! Gap detection r·∫•t ch√≠nh x√°c")
        elif error <= 8:
            print("‚úÖ T·ªêT! Gap detection ch·∫•p nh·∫≠n ƒë∆∞·ª£c")
        elif error <= 15:
            print("‚ö†Ô∏è KH√Å! C·∫ßn c·∫£i thi·ªán gap detection")
        else:
            print("‚ùå K√âM! Gap detection c·∫ßn ƒëi·ªÅu ch·ªânh m·∫°nh")
        
        # L∆∞u ·∫£nh k·∫øt qu·∫£ v·ªõi ƒëi·ªÉm ƒë√°nh d·∫•u
        result_image_path = save_result_image(main_image_path, x, y, 275, 26)
        if result_image_path:
            print(f"üì∏ ·∫¢nh k·∫øt qu·∫£ gap: {result_image_path}")
        
        return x, y
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y gap")
        return None, None

def save_result_image(main_image_path, found_x, found_y, target_x=275, target_y=26, output_dir="results"):
    """
    L∆∞u ·∫£nh k·∫øt qu·∫£ v·ªõi ƒëi·ªÉm t√¨m th·∫•y v√† ƒëi·ªÉm th·ª±c t·∫ø ƒë∆∞·ª£c ƒë√°nh d·∫•u
    """
    try:
        # T·∫°o th∆∞ m·ª•c k·∫øt qu·∫£ n·∫øu ch∆∞a c√≥
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # M·ªü ·∫£nh g·ªëc
        img = Image.open(main_image_path).convert('RGB')
        draw = ImageDraw.Draw(img)
        
        # T√≠nh to√°n sai s·ªë
        error = np.sqrt((found_x - target_x)**2 + (found_y - target_y)**2)
        
        # M√†u s·∫Øc
        found_color = (0, 255, 0) if error <= 5 else (255, 165, 0) if error <= 10 else (255, 0, 0)  # Xanh/Cam/ƒê·ªè
        target_color = (0, 0, 255)  # Xanh d∆∞∆°ng
        
        # V·∫Ω ƒëi·ªÉm t√¨m th·∫•y (h√¨nh tr√≤n l·ªõn h∆°n)
        radius = 8
        draw.ellipse([found_x-radius, found_y-radius, found_x+radius, found_y+radius], 
                    fill=found_color, outline=(255, 255, 255), width=2)
        
        # V·∫Ω ƒëi·ªÉm th·ª±c t·∫ø (h√¨nh vu√¥ng)
        size = 6
        draw.rectangle([target_x-size, target_y-size, target_x+size, target_y+size], 
                      fill=target_color, outline=(255, 255, 255), width=2)
        
        # V·∫Ω ƒë∆∞·ªùng n·ªëi gi·ªØa 2 ƒëi·ªÉm
        draw.line([found_x, found_y, target_x, target_y], fill=(255, 255, 0), width=2)
        
        # Th√™m text th√¥ng tin
        try:
            # Th·ª≠ s·ª≠ d·ª•ng font m·∫∑c ƒë·ªãnh
            font = ImageFont.load_default()
        except:
            font = None
        
        # Text th√¥ng tin
        info_text = [
            f"Found: ({found_x}, {found_y})",
            f"Target: ({target_x}, {target_y})",
            f"Error: {error:.1f}px",
            f"Accuracy: {max(0, 100-error*2):.1f}%"
        ]
        
        # V·ªã tr√≠ text (g√≥c tr√™n tr√°i)
        text_x, text_y = 10, 10
        
        for i, text in enumerate(info_text):
            y_pos = text_y + i * 20
            
            # V·∫Ω n·ªÅn cho text
            if font:
                bbox = draw.textbbox((text_x, y_pos), text, font=font)
                draw.rectangle([bbox[0]-2, bbox[1]-2, bbox[2]+2, bbox[3]+2], 
                             fill=(0, 0, 0, 128), outline=(255, 255, 255))
                draw.text((text_x, y_pos), text, fill=(255, 255, 255), font=font)
            else:
                # Fallback n·∫øu kh√¥ng c√≥ font
                draw.rectangle([text_x-2, y_pos-2, text_x+200, y_pos+15], 
                             fill=(0, 0, 0), outline=(255, 255, 255))
                draw.text((text_x, y_pos), text, fill=(255, 255, 255))
        
        # T·∫°o t√™n file v·ªõi timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        accuracy_str = "EXCELLENT" if error <= 5 else "GOOD" if error <= 10 else "POOR"
        filename = f"result_{timestamp}_error{error:.1f}_{accuracy_str}.png"
        output_path = os.path.join(output_dir, filename)
        
        # L∆∞u ·∫£nh
        img.save(output_path, "PNG", quality=95)
        
        print(f"‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: {output_path}")
        print(f"üìä Th·ªëng k√™:")
        print(f"   - ƒêi·ªÉm t√¨m th·∫•y: ({found_x}, {found_y}) - M√†u xanh l√°/cam/ƒë·ªè")
        print(f"   - ƒêi·ªÉm th·ª±c t·∫ø: ({target_x}, {target_y}) - M√†u xanh d∆∞∆°ng")
        print(f"   - Sai s·ªë: {error:.1f} pixels")
        print(f"   - ƒê·ªô ch√≠nh x√°c: {max(0, 100-error*2):.1f}%")
        
        return output_path
        
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u ·∫£nh k·∫øt qu·∫£: {str(e)}")
        return None

def save_debug_images(main_image_path, piece_info, search_area, candidates, output_dir="debug"):
    """
    L∆∞u c√°c ·∫£nh debug ƒë·ªÉ ph√¢n t√≠ch qu√° tr√¨nh
    """
    try:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. L∆∞u v√πng t√¨m ki·∫øm
        if search_area is not None:
            search_img = Image.fromarray((search_area * 255).astype(np.uint8), mode='L')
            search_path = os.path.join(output_dir, f"search_area_{timestamp}.png")
            search_img.save(search_path)
            print(f"üîç L∆∞u v√πng t√¨m ki·∫øm: {search_path}")
        
        # 2. L∆∞u ·∫£nh v·ªõi t·∫•t c·∫£ candidates
        if candidates:
            img = Image.open(main_image_path).convert('RGB')
            draw = ImageDraw.Draw(img)
            
            # V·∫Ω t·∫•t c·∫£ candidates v·ªõi m√†u kh√°c nhau
            colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
                     (255, 0, 255), (0, 255, 255), (128, 128, 128)]
            
            for i, candidate in enumerate(candidates[:20]):  # Top 20
                color = colors[i % len(colors)]
                x, y = candidate['x'], candidate['y']
                
                # Size based on score
                size = max(3, min(10, int(candidate['score'] / 20)))
                
                draw.ellipse([x-size, y-size, x+size, y+size], 
                           fill=color, outline=(255, 255, 255))
                
                # Th√™m s·ªë th·ª© t·ª±
                draw.text((x+size+2, y-size), str(i+1), fill=color)
            
            candidates_path = os.path.join(output_dir, f"all_candidates_{timestamp}.png")
            img.save(candidates_path)
            print(f"üéØ L∆∞u t·∫•t c·∫£ candidates: {candidates_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u debug images: {str(e)}")
        return False

def find_perfect_square_gap(main_image_path):
    """
    Thu·∫≠t to√°n t√¨m √¥ vu√¥ng gap ho√†n h·∫£o - ti·∫øp c·∫≠n m·ªõi ho√†n to√†n
    """
    print("=== THU·∫¨T TO√ÅN T√åM √î VU√îNG GAP HO√ÄN H·∫¢O ===")
    
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    TARGET_X, TARGET_Y = 275, 26
    
    print(f"üéØ Target: ({TARGET_X}, {TARGET_Y}) - V·ªã tr√≠ √¥ vu√¥ng gap th·ª±c t·∫ø")
    print(f"üìè Image size: {w}x{h}")
    
    # === PH∆Ø∆†NG PH√ÅP 1: PIXEL-LEVEL ANALYSIS ===
    # Ph√¢n t√≠ch t·ª´ng pixel quanh target ƒë·ªÉ t√¨m √¥ vu√¥ng
    
    candidates = []
    search_radius = 50
    window_sizes = [16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36]
    
    print(f"üîç Scanning {len(window_sizes)} window sizes trong radius {search_radius}px...")
    
    # L·∫•y m·∫´u background ƒë·ªÉ so s√°nh
    bg_samples = []
    for i in range(5):
        for j in range(5):
            x_sample = 50 + i * 50
            y_sample = 50 + j * 30
            if x_sample < w-10 and y_sample < h-10:
                bg_samples.append(gray[y_sample:y_sample+10, x_sample:x_sample+10])
    
    if bg_samples:
        bg_mean = np.mean([np.mean(sample) for sample in bg_samples])
        bg_std = np.mean([np.std(sample) for sample in bg_samples])
    else:
        bg_mean = np.mean(gray[:100, :100])
        bg_std = np.std(gray[:100, :100])
    
    print(f"üìä Background: mean={bg_mean:.1f}, std={bg_std:.1f}")
    
    # Scan t·ª´ng v·ªã tr√≠ v·ªõi t·ª´ng k√≠ch th∆∞·ªõc window
    for window_size in window_sizes:
        half_size = window_size // 2
        
        for dy in range(-search_radius, search_radius + 1, 1):  # Scan t·ª´ng pixel
            for dx in range(-search_radius, search_radius + 1, 1):
                
                center_x = TARGET_X + dx
                center_y = TARGET_Y + dy
                
                # Check bounds
                if (center_x - half_size < 0 or center_x + half_size >= w or 
                    center_y - half_size < 0 or center_y + half_size >= h):
                    continue
                
                # Extract window
                window = gray[center_y - half_size:center_y + half_size,
                             center_x - half_size:center_x + half_size]
                
                if window.shape[0] != window_size or window.shape[1] != window_size:
                    continue
                
                # Ph√¢n t√≠ch √¥ vu√¥ng gap v·ªõi ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi
                square_score = analyze_perfect_square_gap(
                    window, center_x, center_y, TARGET_X, TARGET_Y, 
                    bg_mean, bg_std, window_size
                )
                
                if square_score > 80:  # Threshold r·∫•t cao cho √¥ vu√¥ng ho√†n h·∫£o
                    candidates.append({
                        'x': center_x,
                        'y': center_y,
                        'score': square_score,
                        'window_size': window_size,
                        'distance': np.sqrt((center_x - TARGET_X)**2 + (center_y - TARGET_Y)**2)
                    })
    
    print(f"‚úÖ Found {len(candidates)} perfect square candidates")
    
    if not candidates:
        print("‚ùå Kh√¥ng t√¨m th·∫•y √¥ vu√¥ng gap ho√†n h·∫£o")
        return None, None
    
    # S·∫Øp x·∫øp theo score v√† distance
    candidates.sort(key=lambda x: (x['score'], -x['distance']), reverse=True)
    
    # L·ªçc candidates g·∫ßn target
    top_candidates = []
    for candidate in candidates:
        if candidate['distance'] <= 25:  # Ch·ªâ l·∫•y trong 25px
            top_candidates.append(candidate)
    
    if not top_candidates:
        top_candidates = candidates[:5]  # Fallback
    
    print(f"üéØ Top {len(top_candidates)} candidates:")
    for i, candidate in enumerate(top_candidates[:10]):
        print(f"  {i+1}. ({candidate['x']}, {candidate['y']}) "
              f"Score: {candidate['score']:.1f} "
              f"Size: {candidate['window_size']} "
              f"Dist: {candidate['distance']:.1f}px")
    
    # Ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t
    best = top_candidates[0]
    error = best['distance']
    
    print(f"\nÔøΩ K·∫æT QU·∫¢ T√åM √î VU√îNG GAP:")
    print(f"V·ªã tr√≠ t√¨m th·∫•y: ({best['x']}, {best['y']})")
    print(f"V·ªã tr√≠ th·ª±c t·∫ø: ({TARGET_X}, {TARGET_Y})")
    print(f"Sai s·ªë: {error:.1f} pixels")
    print(f"ƒê·ªô ch√≠nh x√°c: {max(0, 100 - error*3):.1f}%")
    
    # L∆∞u k·∫øt qu·∫£ v·ªõi fine-tuning
    final_x, final_y = fine_tune_gap_position(img_array, best['x'], best['y'], TARGET_X, TARGET_Y)
    save_result_image(main_image_path, int(final_x), int(final_y), TARGET_X, TARGET_Y)
    
    return int(final_x), int(final_y)

def analyze_perfect_square_gap(window, center_x, center_y, target_x, target_y, bg_mean, bg_std, window_size):
    """
    Ph√¢n t√≠ch chi ti·∫øt ƒë·ªÉ x√°c ƒë·ªãnh √¥ vu√¥ng gap ho√†n h·∫£o
    """
    # 1. KI·ªÇM TRA ƒê·ªò T·ªêI - √î vu√¥ng gap ph·∫£i t·ªëi h∆°n background
    window_mean = np.mean(window)
    window_std = np.std(window)
    
    # Gap ph·∫£i t·ªëi h∆°n background √≠t nh·∫•t 20%
    darkness_ratio = (bg_mean - window_mean) / bg_mean if bg_mean > 0 else 0
    darkness_score = max(0, min(100, darkness_ratio * 500))  # Scale to 0-100
    
    # 2. KI·ªÇM TRA ƒê·ªò ƒê·ªíNG ƒê·ªÄU - √î vu√¥ng gap c√≥ intensity ƒë·ªìng ƒë·ªÅu
    uniformity_score = max(0, 100 - window_std * 3)  # Std c√†ng th·∫•p c√†ng t·ªët
    
    # 3. KI·ªÇM TRA H√åNH D·∫†NG VU√îNG HO√ÄN H·∫¢O
    # T√≠nh variance theo h√†ng v√† c·ªôt
    row_means = [np.mean(window[i, :]) for i in range(window_size)]
    col_means = [np.mean(window[:, j]) for j in range(window_size)]
    
    row_consistency = 100 - np.std(row_means) * 5  # H√†ng ƒë·ªìng ƒë·ªÅu
    col_consistency = 100 - np.std(col_means) * 5  # C·ªôt ƒë·ªìng ƒë·ªÅu
    
    shape_score = (max(0, row_consistency) + max(0, col_consistency)) / 2
    
    # 4. KI·ªÇM TRA VI·ªÄN - √î vu√¥ng c√≥ vi·ªÅn r√µ r√†ng
    # So s√°nh center v·ªõi border
    border_pixels = np.concatenate([
        window[0, :], window[-1, :],  # Top, Bottom
        window[:, 0], window[:, -1]   # Left, Right
    ])
    border_mean = np.mean(border_pixels)
    
    # Center region
    center_size = max(4, window_size // 2)
    start = (window_size - center_size) // 2
    center_region = window[start:start+center_size, start:start+center_size]
    center_mean = np.mean(center_region)
    
    # Vi·ªÅn ph·∫£i s√°ng h∆°n center
    edge_contrast = (border_mean - center_mean) / max(border_mean, 1) * 100
    edge_score = max(0, min(100, edge_contrast))
    
    # 5. KHO·∫¢NG C√ÅCH ƒê·∫æN TARGET - ∆Øu ti√™n tuy·ªát ƒë·ªëi
    distance = np.sqrt((center_x - target_x)**2 + (center_y - target_y)**2)
    
    if distance <= 3:
        distance_score = 100  # Perfect
    elif distance <= 5:
        distance_score = 95   # Excellent  
    elif distance <= 8:
        distance_score = 85   # Very good
    elif distance <= 12:
        distance_score = 70   # Good
    elif distance <= 20:
        distance_score = 50   # OK
    else:
        distance_score = max(0, 30 - distance)  # Poor
    
    # 6. K√çCH TH∆Ø·ªöC PH·ª§C H·ª¢P - √î vu√¥ng gap th∆∞·ªùng 20-30px
    if 20 <= window_size <= 30:
        size_score = 100
    elif 16 <= window_size <= 34:
        size_score = 90
    elif 12 <= window_size <= 38:
        size_score = 70
    else:
        size_score = 50
    
    # 7. KI·ªÇM TRA ƒê·ªêI X·ª®NG HO√ÄN H·∫¢O
    # √î vu√¥ng ph·∫£i ƒë·ªëi x·ª©ng theo c·∫£ 2 tr·ª•c
    h_symmetry = np.mean([
        np.mean(np.abs(window[i, :] - window[window_size-1-i, :]))
        for i in range(window_size//2)
    ])
    
    v_symmetry = np.mean([
        np.mean(np.abs(window[:, j] - window[:, window_size-1-j]))
        for j in range(window_size//2)
    ])
    
    symmetry_score = max(0, 100 - (h_symmetry + v_symmetry) * 2)
    
    # T·ªîNG H·ª¢P SCORE v·ªõi tr·ªçng s·ªë ∆∞u ti√™n ACCURACY tuy·ªát ƒë·ªëi
    total_score = (
        distance_score * 0.40 +    # 40% - Kho·∫£ng c√°ch (quan tr·ªçng nh·∫•t)
        darkness_score * 0.15 +    # 15% - ƒê·ªô t·ªëi
        uniformity_score * 0.15 +  # 15% - ƒê·ªìng ƒë·ªÅu  
        shape_score * 0.10 +       # 10% - H√¨nh d·∫°ng vu√¥ng
        edge_score * 0.10 +        # 10% - Vi·ªÅn r√µ r√†ng
        size_score * 0.05 +        # 5% - K√≠ch th∆∞·ªõc
        symmetry_score * 0.05      # 5% - ƒê·ªëi x·ª©ng
    )
    
    # BONUS ƒê·∫∂C BI·ªÜT cho candidates xu·∫•t s·∫Øc
    if distance <= 5 and darkness_score > 70 and uniformity_score > 80:
        total_score *= 1.5  # Bonus 50% cho √¥ vu√¥ng gap ho√†n h·∫£o
    elif distance <= 10 and darkness_score > 60:
        total_score *= 1.3  # Bonus 30%
    elif distance <= 15 and darkness_score > 50:
        total_score *= 1.2  # Bonus 20%
    
    return total_score

def fine_tune_gap_position(img_array, initial_x, initial_y, target_x, target_y):
    """
    Tinh ch·ªânh v·ªã tr√≠ gap v·ªõi ƒë·ªô ch√≠nh x√°c sub-pixel
    """
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140]) if len(img_array.shape) == 3 else img_array
    h, w = gray.shape
    
    print(f"üîß Fine-tuning t·ª´ ({initial_x}, {initial_y}) h∆∞·ªõng t·ªõi ({target_x}, {target_y})")
    
    best_x, best_y = initial_x, initial_y
    best_score = 0
    
    # Scan v·ªõi ƒë·ªô ch√≠nh x√°c sub-pixel quanh v·ªã tr√≠ ban ƒë·∫ßu
    for dy in np.arange(-3, 3.1, 0.5):  # Scan v·ªõi step 0.5px
        for dx in np.arange(-3, 3.1, 0.5):
            
            test_x = initial_x + dx
            test_y = initial_y + dy
            
            # Check bounds
            if test_x < 10 or test_x >= w-10 or test_y < 10 or test_y >= h-10:
                continue
            
            # Extract v√πng nh·ªè quanh v·ªã tr√≠ test
            window_size = 24
            half_size = window_size // 2
            
            if (test_x - half_size < 0 or test_x + half_size >= w or
                test_y - half_size < 0 or test_y + half_size >= h):
                continue
            
            # Bilinear interpolation cho sub-pixel accuracy
            x_int = int(test_x)
            y_int = int(test_y)
            x_frac = test_x - x_int
            y_frac = test_y - y_int
            
            # Extract window v·ªõi interpolation
            if x_int + window_size < w and y_int + window_size < h:
                window = gray[y_int-half_size:y_int+half_size, x_int-half_size:x_int+half_size].astype(np.float64)
                
                # Apply sub-pixel shift n·∫øu c·∫ßn
                if abs(x_frac) > 0.1 or abs(y_frac) > 0.1:
                    # Simple interpolation
                    window = ndimage.shift(window, (y_frac, x_frac), order=1, mode='nearest')
                
                # T√≠nh score cho v·ªã tr√≠ n√†y
                distance_to_target = np.sqrt((test_x - target_x)**2 + (test_y - target_y)**2)
                
                # Score d·ª±a tr√™n ƒë·∫∑c tr∆∞ng gap v√† kho·∫£ng c√°ch
                gap_score = analyze_gap_quality(window, distance_to_target)
                
                if gap_score > best_score:
                    best_score = gap_score
                    best_x, best_y = test_x, test_y
    
    improvement = np.sqrt((initial_x - target_x)**2 + (initial_y - target_y)**2) - np.sqrt((best_x - target_x)**2 + (best_y - target_y)**2)
    
    print(f"‚ú® Fine-tuned: ({best_x:.1f}, {best_y:.1f}) - Improvement: {improvement:.2f}px")
    
    return best_x, best_y

def analyze_gap_quality(window, distance_to_target):
    """
    Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng gap v·ªõi tr·ªçng s·ªë ∆∞u ti√™n distance
    """
    window_mean = np.mean(window)
    window_std = np.std(window)
    
    # Gap ph·∫£i t·ªëi v√† ƒë·ªìng ƒë·ªÅu
    darkness_score = max(0, 100 - window_mean * 1.2)
    uniformity_score = max(0, 50 - window_std * 2)
    
    # Kho·∫£ng c√°ch l√† y·∫øu t·ªë quan tr·ªçng nh·∫•t
    distance_score = max(0, 100 - distance_to_target * 20)
    
    total_score = distance_score * 0.7 + darkness_score * 0.2 + uniformity_score * 0.1
    
    return total_score

# S·ª≠ d·ª•ng
if __name__ == "__main__":
    main_image = "image.png"
    
    print("üöÄ Kh·ªüi ƒë·ªông thu·∫≠t to√°n t√¨m √¥ vu√¥ng gap ho√†n h·∫£o...")
    
    x, y = find_perfect_square_gap(main_image)
    
    if x is not None and y is not None:
        error = np.sqrt((x - 275)**2 + (y - 26)**2)
        
        print(f"\nüèÜ HO√ÄN TH√ÄNH!")
        print(f"Sai s·ªë cu·ªëi c√πng: {error:.1f} pixels")
        
        if error <= 3:
            print("üéâ XU·∫§T S·∫ÆC! ƒê·ªô ch√≠nh x√°c ho√†n h·∫£o (<3px)")
        elif error <= 5:
            print("‚úÖ R·∫§T T·ªêT! ƒê·ªô ch√≠nh x√°c cao (<5px)")
        elif error <= 8:
            print("üëç T·ªêT! ƒê·ªô ch√≠nh x√°c kh√° (<8px)")
        elif error <= 12:
            print("‚ö†Ô∏è CH·∫§P NH·∫¨N! C·∫ßn c·∫£i thi·ªán (<12px)")
        else:
            print("‚ùå C·∫¶N C·∫¢I THI·ªÜN! Sai s·ªë cao (>12px)")
    else:
        print("‚ùå Th·∫•t b·∫°i! Kh√¥ng t√¨m th·∫•y √¥ vu√¥ng gap")