from PIL import Image
import numpy as np
import cv2
import os
from skimage import feature, filters, morphology, measure
from skimage.segmentation import flood_fill
from scipy import ndimage
from skimage.feature import peak_local_max
# B·ªè import match_template v√¨ kh√¥ng t·ªìn t·∫°i
# from skimage.transform import match_template

def analyze_puzzle_piece_ultra_precise(main_image_path):
    """
    Ph√¢n t√≠ch m·∫£nh gh√©p v·ªõi ƒë·ªô ch√≠nh x√°c si√™u cao
    """
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    
    # T√¨m v√πng m·∫£nh gh√©p ch√≠nh x√°c h∆°n
    # Th·ª≠ nhi·ªÅu v√πng kh√°c nhau ƒë·ªÉ t√¨m piece
    piece_regions = [
        (h*3//4, h, 0, w),           # 1/4 d∆∞·ªõi
        (h*2//3, h, 0, w),           # 1/3 d∆∞·ªõi  
        (h*4//5, h, w//4, w*3//4),   # 1/5 d∆∞·ªõi, gi·ªØa
    ]
    
    best_piece = None
    best_score = 0
    
    for top, bottom, left, right in piece_regions:
        piece_area = gray[top:bottom, left:right]
        piece_h, piece_w = piece_area.shape
        
        if piece_h <= 0 or piece_w <= 0:
            continue
            
        # Multi-threshold edge detection
        edges_canny = feature.canny(piece_area, sigma=1.0, low_threshold=0.08, high_threshold=0.25)
        edges_sobel = filters.sobel(piece_area) > 0.12
        edges_combined = edges_canny | edges_sobel
        
        # Morphological cleaning
        kernel = morphology.disk(1)
        edges_clean = morphology.closing(edges_combined, kernel)
        edges_clean = morphology.opening(edges_clean, kernel)
        
        # Find contours
        contours, _ = cv2.findContours(edges_clean.astype(np.uint8), 
                                       cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            continue
            
        # L·∫•y contour c√≥ area h·ª£p l√Ω (kh√¥ng qu√° l·ªõn, kh√¥ng qu√° nh·ªè)
        valid_contours = []
        total_area = piece_h * piece_w
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if 0.01 * total_area < area < 0.5 * total_area:  # 1% - 50% area
                valid_contours.append(contour)
        
        if not valid_contours:
            continue
            
        # Ch·ªçn contour t·ªët nh·∫•t d·ª±a tr√™n h√¨nh d·∫°ng puzzle piece
        for contour in valid_contours:
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            if perimeter == 0:
                continue
                
            # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
            x, y, w_cont, h_cont = cv2.boundingRect(contour)
            aspect_ratio = w_cont / h_cont if h_cont > 0 else 1
            
            # Circularity
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            
            # Convex hull
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            
            # Compactness
            compactness = area / (w_cont * h_cont) if (w_cont * h_cont) > 0 else 0
            
            # Score cho puzzle piece (puzzle piece c√≥ h√¨nh d·∫°ng ƒë·∫∑c bi·ªát)
            piece_score = (
                (1 - abs(aspect_ratio - 1.0)) * 30 +     # G·∫ßn h√¨nh vu√¥ng
                (1 - circularity) * 40 +                  # Kh√¥ng tr√≤n ho√†n h·∫£o
                (1 - solidity) * 50 +                     # C√≥ l·ªó h·ªïng/indentation
                compactness * 20 +                        # Density
                min(area / 1000, 1.0) * 10               # Size reasonable
            )
            
            if piece_score > best_score:
                best_score = piece_score
                best_piece = {
                    'area': area,
                    'perimeter': perimeter,
                    'width': w_cont,
                    'height': h_cont,
                    'aspect_ratio': aspect_ratio,
                    'circularity': circularity,
                    'solidity': solidity,
                    'compactness': compactness,
                    'contour': contour,
                    'region_offset': (left, top),
                    'score': piece_score
                }
    
    if best_piece:
        print(f"Ph√¢n t√≠ch m·∫£nh gh√©p (Score: {best_piece['score']:.1f}):")
        print(f"  - Di·ªán t√≠ch: {best_piece['area']:.0f} pixels")
        print(f"  - K√≠ch th∆∞·ªõc: {best_piece['width']}x{best_piece['height']}")
        print(f"  - T·ª∑ l·ªá: {best_piece['aspect_ratio']:.2f}")
        print(f"  - ƒê·ªô tr√≤n: {best_piece['circularity']:.3f}")
        print(f"  - ƒê·ªô ƒë·∫∑c: {best_piece['solidity']:.3f}")
        print(f"  - Compactness: {best_piece['compactness']:.3f}")
        
        return best_piece
    
    print("Kh√¥ng t√¨m th·∫•y m·∫£nh gh√©p ph√π h·ª£p")
    return None

def cv2_template_matching(search_area, template):
    """
    S·ª≠ d·ª•ng cv2 ƒë·ªÉ template matching thay th·∫ø cho skimage
    """
    # Ensure both arrays are float32
    search_area_f = search_area.astype(np.float32)
    template_f = template.astype(np.float32)
    
    # Template matching
    result = cv2.matchTemplate(search_area_f, template_f, cv2.TM_CCOEFF_NORMED)
    
    # Find all good matches (threshold = 0.3)
    locations = np.where(result >= 0.3)
    matches = []
    
    for pt in zip(*locations[::-1]):  # Switch columns and rows
        confidence = result[pt[1], pt[0]]
        matches.append((pt[0], pt[1], confidence))
    
    return matches

def find_gap_ultra_precise(main_image_path, piece_info):
    """
    T√¨m gap v·ªõi ƒë·ªô ch√≠nh x√°c si√™u cao
    """
    img = Image.open(main_image_path).convert('RGB')
    img_array = np.array(img)
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    h, w = gray.shape
    
    # V√πng t√¨m ki·∫øm ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a
    search_top = 0
    search_bottom = h // 2  # Ch·ªâ t√¨m n·ª≠a tr√™n
    search_left = w // 8    # B·ªè qua vi·ªÅn tr√°i
    search_right = w * 7 // 8  # B·ªè qua vi·ªÅn ph·∫£i
    
    search_area = gray[search_top:search_bottom, search_left:search_right]
    search_h, search_w = search_area.shape
    
    print(f"V√πng t√¨m ki·∫øm: {search_w}x{search_h}")
    
    # Tham s·ªë t·ª´ m·∫£nh gh√©p
    target_area = piece_info['area']
    target_width = piece_info['width']
    target_height = piece_info['height']
    
    # Tolerance ch·∫∑t ch·∫Ω h∆°n
    area_tolerance = 0.25  # ¬±25%
    min_area = target_area * (1 - area_tolerance)
    max_area = target_area * (1 + area_tolerance)
    
    print(f"T√¨m v√πng gap: {min_area:.0f} - {max_area:.0f} pixels")
    
    all_candidates = []
    
    # === PH∆Ø∆†NG PH√ÅP 1: MULTI-THRESHOLD ANALYSIS ===
    thresholds = [
        np.mean(search_area) - 1.5 * np.std(search_area),
        np.mean(search_area) - 1.0 * np.std(search_area),
        np.mean(search_area) - 0.5 * np.std(search_area),
        np.mean(search_area),
    ]
    
    for i, threshold in enumerate(thresholds):
        binary = search_area < threshold
        
        # Morphological operations
        kernel = morphology.disk(2)
        binary_clean = morphology.opening(binary, kernel)
        binary_clean = morphology.closing(binary_clean, morphology.disk(3))
        
        # Connected components
        labeled = measure.label(binary_clean)
        regions = measure.regionprops(labeled)
        
        for region in regions:
            if min_area <= region.area <= max_area:
                # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
                bbox = region.bbox
                region_width = bbox[3] - bbox[1]
                region_height = bbox[2] - bbox[0]
                
                if region_height == 0:
                    continue
                    
                region_aspect = region_width / region_height
                
                # Ki·ªÉm tra aspect ratio
                aspect_diff = abs(region_aspect - piece_info['aspect_ratio'])
                if aspect_diff < 0.6:  # Ch·∫∑t ch·∫Ω h∆°n
                    centroid_y, centroid_x = region.centroid
                    
                    # Multi-criteria scoring
                    area_score = 1 - abs(region.area - target_area) / target_area
                    aspect_score = 1 - aspect_diff / 0.6
                    eccentricity_score = 1 - region.eccentricity
                    extent_score = region.extent
                    
                    total_score = (
                        area_score * 100 +
                        aspect_score * 80 +
                        eccentricity_score * 30 +
                        extent_score * 20
                    )
                    
                    global_x = int(centroid_x + search_left)
                    global_y = int(centroid_y + search_top)
                    
                    all_candidates.append({
                        'x': global_x,
                        'y': global_y,
                        'score': total_score,
                        'area': region.area,
                        'method': f'threshold_{i}',
                        'details': {
                            'area_score': area_score,
                            'aspect_score': aspect_score,
                            'eccentricity': region.eccentricity,
                            'extent': region.extent
                        }
                    })
    
    # === PH∆Ø∆†NG PH√ÅP 2: ADVANCED EDGE-BASED ANALYSIS ===
    # Multiple edge detection methods
    edges_canny = feature.canny(search_area, sigma=1.0, low_threshold=0.05, high_threshold=0.15)
    edges_sobel = filters.sobel(search_area) > 0.1
    edges_scharr = filters.scharr(search_area) > 0.1
    edges_prewitt = filters.prewitt(search_area) > 0.1
    
    # Combine edges
    edges_combined = edges_canny | edges_sobel | edges_scharr | edges_prewitt
    
    # Morphological processing
    kernel = morphology.disk(2)
    edges_processed = morphology.closing(edges_combined, kernel)
    edges_processed = morphology.opening(edges_processed, morphology.disk(1))
    
    # Find contours
    contours, _ = cv2.findContours(edges_processed.astype(np.uint8), 
                                   cv2.RETR_EXTERNAL, 
                                   cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if min_area <= area <= max_area:
            # T√≠nh centroid
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                
                # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
                perimeter = cv2.arcLength(contour, True)
                circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0
                
                # Bounding box
                x, y, w_cont, h_cont = cv2.boundingRect(contour)
                aspect_ratio = w_cont / h_cont if h_cont > 0 else 1
                
                # Convex hull
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                solidity = area / hull_area if hull_area > 0 else 0
                
                # Scoring
                area_score = 1 - abs(area - target_area) / target_area
                aspect_score = 1 - abs(aspect_ratio - piece_info['aspect_ratio'])
                circ_score = 1 - abs(circularity - piece_info['circularity'])
                solid_score = abs(solidity - piece_info['solidity'])  # Gap should have different solidity
                
                total_score = (
                    area_score * 120 +
                    aspect_score * 60 +
                    circ_score * 40 +
                    solid_score * 30
                )
                
                global_x = cx + search_left
                global_y = cy + search_top
                
                all_candidates.append({
                    'x': global_x,
                    'y': global_y,
                    'score': total_score,
                    'area': area,
                    'method': 'edge_contour',
                    'details': {
                        'area_score': area_score,
                        'aspect_score': aspect_score,
                        'circularity': circularity,
                        'solidity': solidity
                    }
                })
    
    # === PH∆Ø∆†NG PH√ÅP 3: TEMPLATE MATCHING MULTI-SCALE ===
    scales = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]
    
    for scale in scales:
        template_size = int(np.sqrt(target_area) * scale)
        if template_size < 10 or template_size > min(search_h, search_w) // 2:
            continue
            
        template = create_precise_gap_template(template_size, piece_info)
        
        # Template matching s·ª≠ d·ª•ng cv2
        matches = cv2_template_matching(search_area, template)
        
        for match_x, match_y, confidence in matches:
            if confidence > 0.3:  # Threshold
                # Convert to global coordinates
                global_x = match_x + template_size // 2 + search_left
                global_y = match_y + template_size // 2 + search_top
                
                # Estimate area
                estimated_area = template_size * template_size * 0.8
                area_score = 1 - abs(estimated_area - target_area) / target_area
                
                total_score = confidence * 150 + area_score * 50
                
                all_candidates.append({
                    'x': global_x,
                    'y': global_y,
                    'score': total_score,
                    'area': estimated_area,
                    'method': f'template_{scale:.1f}',
                    'details': {
                        'confidence': confidence,
                        'area_score': area_score,
                        'template_size': template_size
                    }
                })
    
    # === ENSEMBLE V√Ä FILTERING ===
    if all_candidates:
        print(f"T·ªïng c·ªông {len(all_candidates)} candidates t·ª´ t·∫•t c·∫£ ph∆∞∆°ng ph√°p")
        
        # S·∫Øp x·∫øp theo score
        all_candidates.sort(key=lambda x: x['score'], reverse=True)
        
        # Advanced Non-Maximum Suppression
        final_candidates = advanced_nms(all_candidates, 
                                       distance_threshold=25, 
                                       score_threshold=30)
        
        # Ensemble scoring
        ensemble_candidates = ensemble_scoring(final_candidates)
        
        print(f"Sau filtering: {len(ensemble_candidates)} candidates")
        
        # In top candidates
        print("\nTop 10 candidates:")
        for i, candidate in enumerate(ensemble_candidates[:10]):
            error = np.sqrt((candidate['x'] - 275)**2 + (candidate['y'] - 26)**2)
            print(f"  {i+1}. ({candidate['x']}, {candidate['y']}) "
                  f"- Score: {candidate['score']:.1f} "
                  f"- Method: {candidate['method']} "
                  f"- Error: {error:.1f}")
        
        # Ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t
        best_candidate = ensemble_candidates[0]
        return best_candidate['x'], best_candidate['y']
    
    return None, None

def create_precise_gap_template(size, piece_info):
    """
    T·∫°o template ch√≠nh x√°c d·ª±a tr√™n th√¥ng tin m·∫£nh gh√©p
    """
    template = np.ones((size, size)) * 128  # Background
    center = size // 2
    
    # T·∫°o h√¨nh d·∫°ng gap d·ª±a tr√™n ƒë·∫∑c tr∆∞ng piece
    if piece_info['circularity'] > 0.6:  # N·∫øu piece tr√≤n
        # Gap h√¨nh tr√≤n
        radius = size // 3
        y, x = np.ogrid[:size, :size]
        mask = (x - center)**2 + (y - center)**2 <= radius**2
        template[mask] = 80
    else:
        # Gap h√¨nh vu√¥ng/ch·ªØ nh·∫≠t
        w_gap = size // 3
        h_gap = int(w_gap / piece_info['aspect_ratio'])
        
        top = center - h_gap // 2
        bottom = center + h_gap // 2
        left = center - w_gap // 2
        right = center + w_gap // 2
        
        template[top:bottom, left:right] = 80
    
    # Th√™m indentations d·ª±a tr√™n solidity
    if piece_info['solidity'] < 0.8:  # Piece c√≥ nhi·ªÅu indentation
        indent_size = max(2, size // 12)
        # Top indent
        template[0:indent_size, center-indent_size:center+indent_size] = 100
        # Bottom indent
        template[size-indent_size:size, center-indent_size:center+indent_size] = 100
        # Left indent
        template[center-indent_size:center+indent_size, 0:indent_size] = 100
        # Right indent
        template[center-indent_size:center+indent_size, size-indent_size:size] = 100
    
    # Smooth template
    template = filters.gaussian(template, sigma=1.0)
    
    return template

def advanced_nms(candidates, distance_threshold=20, score_threshold=0):
    """
    Advanced Non-Maximum Suppression
    """
    if not candidates:
        return []
    
    # Filter by score threshold
    candidates = [c for c in candidates if c['score'] >= score_threshold]
    
    # Sort by score descending
    candidates = sorted(candidates, key=lambda x: x['score'], reverse=True)
    
    filtered = []
    for candidate in candidates:
        x, y = candidate['x'], candidate['y']
        
        # Check distance to existing candidates
        too_close = False
        for existing in filtered:
            distance = np.sqrt((x - existing['x'])**2 + (y - existing['y'])**2)
            if distance < distance_threshold:
                too_close = True
                break
        
        if not too_close:
            filtered.append(candidate)
    
    return filtered

def ensemble_scoring(candidates):
    """
    Ensemble scoring ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
    """
    if len(candidates) <= 1:
        return candidates
    
    # Group candidates by proximity
    groups = []
    for candidate in candidates:
        added_to_group = False
        for group in groups:
            # Check if candidate is close to any member of the group
            for member in group:
                distance = np.sqrt((candidate['x'] - member['x'])**2 + 
                                 (candidate['y'] - member['y'])**2)
                if distance < 40:  # Group threshold
                    group.append(candidate)
                    added_to_group = True
                    break
            if added_to_group:
                break
        
        if not added_to_group:
            groups.append([candidate])
    
    # Create ensemble candidates
    ensemble_candidates = []
    for group in groups:
        if len(group) == 1:
            ensemble_candidates.append(group[0])
        else:
            # Weighted average
            total_weight = sum(c['score'] for c in group)
            if total_weight > 0:
                ensemble_x = sum(c['x'] * c['score'] for c in group) / total_weight
                ensemble_y = sum(c['y'] * c['score'] for c in group) / total_weight
                ensemble_score = sum(c['score'] for c in group) / len(group) * 1.2  # Bonus for consensus
                
                ensemble_candidates.append({
                    'x': int(ensemble_x),
                    'y': int(ensemble_y),
                    'score': ensemble_score,
                    'area': sum(c['area'] for c in group) / len(group),
                    'method': f'ensemble_{len(group)}',
                    'group_size': len(group)
                })
    
    # Sort by score
    ensemble_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    return ensemble_candidates

def find_puzzle_gap_ultimate_precision(main_image_path):
    """
    Thu·∫≠t to√°n si√™u ch√≠nh x√°c cu·ªëi c√πng
    """
    print("=== THU·∫¨T TO√ÅN SI√äU CH√çNH X√ÅC TRI·ªÜT ƒê·ªÇ ===")
    print("Target: (275, 26)")
    
    # B∆∞·ªõc 1: Ph√¢n t√≠ch m·∫£nh gh√©p si√™u ch√≠nh x√°c
    piece_info = analyze_puzzle_piece_ultra_precise(main_image_path)
    if piece_info is None:
        print("‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch m·∫£nh gh√©p")
        return None, None
    
    # B∆∞·ªõc 2: T√¨m gap v·ªõi ƒë·ªô ch√≠nh x√°c si√™u cao
    x, y = find_gap_ultra_precise(main_image_path, piece_info)
    
    if x is not None and y is not None:
        error = np.sqrt((x - 275)**2 + (y - 26)**2)
        
        print(f"\nüéØ K·∫æT QU·∫¢ SI√äU CH√çNH X√ÅC:")
        print(f"V·ªã tr√≠ t√¨m th·∫•y: ({x}, {y})")
        print(f"V·ªã tr√≠ th·ª±c t·∫ø: (275, 26)")
        print(f"Sai s·ªë: {error:.1f} pixels")
        print(f"ƒê·ªô ch√≠nh x√°c: {max(0, 100 - error*2):.1f}%")
        
        if error <= 2:
            print("üéØ SI√äU XU·∫§T S·∫ÆC! Ch√≠nh x√°c tri·ªát ƒë·ªÉ")
        elif error <= 5:
            print("üéØ XU·∫§T S·∫ÆC! Ch√≠nh x√°c cao")
        elif error <= 10:
            print("‚úÖ T·ªêT! Ch·∫•p nh·∫≠n ƒë∆∞·ª£c")
        else:
            print("‚ö†Ô∏è C·∫ßn ƒëi·ªÅu ch·ªânh")
        
        return x, y
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y gap")
        return None, None

import base64
import io
import json
from flask import Flask, request, jsonify
import traceback
import tempfile
import os

def decode_base64_image(base64_string):
    """
    Decode base64 string th√†nh PIL Image
    """
    try:
        # Lo·∫°i b·ªè header n·∫øu c√≥ (data:image/png;base64,)
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]
        
        # Decode base64
        image_data = base64.b64decode(base64_string)
        
        # T·∫°o PIL Image t·ª´ bytes
        image = Image.open(io.BytesIO(image_data))
        
        return image
    except Exception as e:
        print(f"L·ªói decode base64: {e}")
        return None

def save_temp_image(image, format='PNG'):
    """
    L∆∞u PIL Image v√†o file t·∫°m th·ªùi
    """
    try:
        # T·∫°o file t·∫°m th·ªùi
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f'.{format.lower()}')
        
        # L∆∞u image
        image.save(temp_file.name, format=format)
        
        return temp_file.name
    except Exception as e:
        print(f"L·ªói l∆∞u file t·∫°m: {e}")
        return None

def process_captcha_image(base64_image):
    """
    X·ª≠ l√Ω h√¨nh ·∫£nh captcha t·ª´ base64 v√† tr·∫£ v·ªÅ t·ªça ƒë·ªô
    """
    try:
        print("üîç B·∫Øt ƒë·∫ßu x·ª≠ l√Ω captcha...")
        
        # Decode base64 th√†nh image
        image = decode_base64_image(base64_image)
        if image is None:
            return {
                'success': False,
                'error': 'Kh√¥ng th·ªÉ decode base64 image',
                'coordinates': None
            }
        
        print(f"‚úÖ Decode th√†nh c√¥ng, k√≠ch th∆∞·ªõc: {image.size}")
        
        # L∆∞u v√†o file t·∫°m th·ªùi
        temp_path = save_temp_image(image, 'PNG')
        if temp_path is None:
            return {
                'success': False,
                'error': 'Kh√¥ng th·ªÉ l∆∞u file t·∫°m th·ªùi',
                'coordinates': None
            }
        
        print(f"üìÅ L∆∞u file t·∫°m: {temp_path}")
        
        try:
            # X·ª≠ l√Ω v·ªõi thu·∫≠t to√°n si√™u ch√≠nh x√°c
            x, y = find_puzzle_gap_ultimate_precision(temp_path)
            
            if x is not None and y is not None:
                # ƒêi·ªÅu ch·ªânh t·ªça ƒë·ªô (n·∫øu c·∫ßn)
                adjusted_x = x - 18  # Theo code g·ªëc
                adjusted_y = y
                
                result = {
                    'success': True,
                    'coordinates': {
                        'x': adjusted_x,
                        'y': adjusted_y,
                        'raw_x': x,
                        'raw_y': y
                    },
                    'message': 'T√¨m th·∫•y v·ªã tr√≠ puzzle gap th√†nh c√¥ng'
                }
                
                print(f"üéØ Th√†nh c√¥ng: ({adjusted_x}, {adjusted_y})")
                return result
            else:
                return {
                    'success': False,
                    'error': 'Kh√¥ng t√¨m th·∫•y v·ªã tr√≠ puzzle gap',
                    'coordinates': None
                }
                
        finally:
            # X√≥a file t·∫°m th·ªùi
            try:
                os.unlink(temp_path)
                print(f"üóëÔ∏è ƒê√£ x√≥a file t·∫°m: {temp_path}")
            except:
                pass
        
    except Exception as e:
        error_msg = f"L·ªói x·ª≠ l√Ω: {str(e)}"
        print(f"‚ùå {error_msg}")
        print(traceback.format_exc())
        
        return {
            'success': False,
            'error': error_msg,
            'coordinates': None
        }

def create_flask_app():
    """
    T·∫°o Flask app v·ªõi API endpoints
    """
    app = Flask(__name__)
    
    @app.route('/health', methods=['GET'])
    def health_check():
        """Health check endpoint"""
        return jsonify({
            'status': 'healthy',
            'service': 'Captcha Puzzle Solver',
            'version': '1.0.0'
        })
    
    @app.route('/solve-captcha', methods=['POST'])
    def solve_captcha():
        """
        API endpoint ƒë·ªÉ x·ª≠ l√Ω captcha
        Body: {
            "image": "base64_string",
            "format": "png" (optional)
        }
        """
        try:
            # Ki·ªÉm tra content type
            if not request.is_json:
                return jsonify({
                    'success': False,
                    'error': 'Content-Type ph·∫£i l√† application/json'
                }), 400
            
            # L·∫•y data t·ª´ request
            data = request.get_json()
            
            if not data or 'image' not in data:
                return jsonify({
                    'success': False,
                    'error': 'Thi·∫øu tr∆∞·ªùng "image" trong request body'
                }), 400
            
            base64_image = data['image']
            
            if not base64_image:
                return jsonify({
                    'success': False,
                    'error': 'Base64 image kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'
                }), 400
            
            # X·ª≠ l√Ω captcha
            result = process_captcha_image(base64_image)
            
            if result['success']:
                return jsonify(result), 200
            else:
                return jsonify(result), 422  # Unprocessable Entity
            
        except Exception as e:
            error_msg = f"L·ªói server: {str(e)}"
            print(f"‚ùå {error_msg}")
            print(traceback.format_exc())
            
            return jsonify({
                'success': False,
                'error': error_msg,
                'coordinates': None
            }), 500
    
    @app.route('/solve-captcha-batch', methods=['POST'])
    def solve_captcha_batch():
        """
        API endpoint ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu captcha c√πng l√∫c
        Body: {
            "images": ["base64_string1", "base64_string2", ...],
            "format": "png" (optional)
        }
        """
        try:
            if not request.is_json:
                return jsonify({
                    'success': False,
                    'error': 'Content-Type ph·∫£i l√† application/json'
                }), 400
            
            data = request.get_json()
            
            if not data or 'images' not in data:
                return jsonify({
                    'success': False,
                    'error': 'Thi·∫øu tr∆∞·ªùng "images" trong request body'
                }), 400
            
            images = data['images']
            
            if not isinstance(images, list) or len(images) == 0:
                return jsonify({
                    'success': False,
                    'error': 'Tr∆∞·ªùng "images" ph·∫£i l√† array kh√¥ng r·ªóng'
                }), 400
            
            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ tr√°nh qu√° t·∫£i
            if len(images) > 10:
                return jsonify({
                    'success': False,
                    'error': 'T·ªëi ƒëa 10 ·∫£nh m·ªói l·∫ßn x·ª≠ l√Ω'
                }), 400
            
            # X·ª≠ l√Ω t·ª´ng ·∫£nh
            results = []
            for i, base64_image in enumerate(images):
                print(f"üîÑ X·ª≠ l√Ω ·∫£nh {i+1}/{len(images)}")
                
                result = process_captcha_image(base64_image)
                result['index'] = i
                results.append(result)
            
            # Th·ªëng k√™ k·∫øt qu·∫£
            success_count = sum(1 for r in results if r['success'])
            
            return jsonify({
                'success': True,
                'total': len(images),
                'success_count': success_count,
                'failed_count': len(images) - success_count,
                'results': results
            }), 200
            
        except Exception as e:
            error_msg = f"L·ªói server: {str(e)}"
            print(f"‚ùå {error_msg}")
            print(traceback.format_exc())
            
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
    
    return app

def run_api_server(host='0.0.0.0', port=8080, debug=False):
    """
    Ch·∫°y API server
    """
    app = create_flask_app()
    
    print("üöÄ Kh·ªüi ƒë·ªông Captcha Puzzle Solver API...")
    print(f"üì° Server: http://{host}:{port}")
    print("üìã Endpoints:")
    print("  GET  /health - Health check")
    print("  POST /solve-captcha - X·ª≠ l√Ω 1 captcha")
    print("  POST /solve-captcha-batch - X·ª≠ l√Ω nhi·ªÅu captcha")
    print("\nüìñ V√≠ d·ª• s·ª≠ d·ª•ng:")
    print("""
curl -X POST http://localhost:8080/solve-captcha \\
  -H "Content-Type: application/json" \\
  -d '{
    "image": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=="
  }'
    """)
    
    # Use Gunicorn for production
    if os.environ.get('FLASK_ENV') == 'production':
        import gunicorn.app.base
        
        class StandaloneApplication(gunicorn.app.base.BaseApplication):
            def __init__(self, app, options=None):
                self.options = options or {}
                self.application = app
                super().__init__()
            
            def load_config(self):
                for key, value in self.options.items():
                    self.cfg.set(key.lower(), value)
            
            def load(self):
                return self.application
        
        options = {
            'bind': f'{host}:{port}',
            'workers': 2,
            'worker_class': 'sync',
            'worker_connections': 1000,
            'timeout': 300,
            'keepalive': 5,
            'max_requests': 1000,
            'max_requests_jitter': 100,
            'log_level': 'info'
        }
        
        StandaloneApplication(app, options).run()
    else:
        app.run(host=host, port=port, debug=debug)

# H√†m helper ƒë·ªÉ test
def test_with_local_image(image_path):
    """
    Test function v·ªõi ·∫£nh local
    """
    try:
        # ƒê·ªçc ·∫£nh v√† convert sang base64
        with open(image_path, 'rb') as f:
            image_data = f.read()
            base64_string = base64.b64encode(image_data).decode('utf-8')
        
        print(f"üì∑ Test v·ªõi ·∫£nh: {image_path}")
        print(f"üì¶ Base64 length: {len(base64_string)}")
        
        # X·ª≠ l√Ω
        result = process_captcha_image(base64_string)
        
        print("üîç K·∫øt qu·∫£:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        return result
        
    except Exception as e:
        print(f"‚ùå L·ªói test: {e}")
        return None

# S·ª≠ d·ª•ng
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'api':
            # Ch·∫°y API server
            host = sys.argv[2] if len(sys.argv) > 2 else '0.0.0.0'
            port = int(sys.argv[3]) if len(sys.argv) > 3 else int(os.environ.get('PORT', 8080))
            debug = os.environ.get('FLASK_ENV') != 'production'
            run_api_server(host=host, port=port, debug=debug)
            
        elif command == 'test':
            # Test v·ªõi ·∫£nh local
            image_path = sys.argv[2] if len(sys.argv) > 2 else 'image.png'
            test_with_local_image(image_path)
            
        elif command == 'solve':
            # X·ª≠ l√Ω tr·ª±c ti·∫øp
            image_path = sys.argv[2] if len(sys.argv) > 2 else 'image.png'
            x, y = find_puzzle_gap_ultimate_precision(image_path)
            
            if x is not None and y is not None:
                print(f"\nüèÜ HO√ÄN TH√ÄNH SI√äU CH√çNH X√ÅC!")
                print(f"K·∫øt qu·∫£ cu·ªëi c√πng: ({x-18}, {y})")
            else:
                print("‚ùå Th·∫•t b·∫°i")
        else:
            print("‚ùå L·ªánh kh√¥ng h·ª£p l·ªá!")
            print("S·ª≠ d·ª•ng:")
            print("  python resolveCaptcha.py api [host] [port]     - Ch·∫°y API server")
            print("  python resolveCaptcha.py test [image_path]     - Test v·ªõi ·∫£nh local")
            print("  python resolveCaptcha.py solve [image_path]    - X·ª≠ l√Ω tr·ª±c ti·∫øp")
    else:
        # M·∫∑c ƒë·ªãnh: x·ª≠ l√Ω tr·ª±c ti·∫øp
        main_image = "image.png"
        
        x, y = find_puzzle_gap_ultimate_precision(main_image)
        
        if x is not None and y is not None:
            print(f"\nüèÜ HO√ÄN TH√ÄNH SI√äU CH√çNH X√ÅC!")
            print(f"K·∫øt qu·∫£ cu·ªëi c√πng: ({x-18}, {y})")
        else:
            print("‚ùå Th·∫•t b·∫°i")